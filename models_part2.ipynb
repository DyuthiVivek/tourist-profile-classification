{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_preprocessed.csv')\n",
    "test = pd.read_csv('test_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = [ 'mainland_nights', 'island_nights', 'ratio', 'total_nights', 'male_count', 'female_count', 'total_travellers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train[num_features] = scaler.fit_transform(train[num_features])\n",
    "test[num_features] = scaler.transform(test[num_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(columns='visitor_nation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_id = test['trip_ID']\n",
    "test_data = test.drop(columns='trip_ID')\n",
    "\n",
    "categories = train['category']\n",
    "train_data = train.drop(columns='category')\n",
    "\n",
    "assert (train_data.columns == test_data.columns).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert into tensor\n",
    "X = torch.tensor(train_data.values, dtype=torch.float32)\n",
    "y = torch.tensor(categories.values, dtype=torch.long)\n",
    "\n",
    "X_test = torch.tensor(test_data.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X, y = smote.fit_resample(X, y)\n",
    "\n",
    "# X = torch.tensor(X, dtype=torch.float32)\n",
    "# y = torch.tensor(y, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swetha/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# define the neural network architecture\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(27, 128)\n",
    "        self.fc2 = nn.Linear(128, 64) \n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 16)\n",
    "        self.fc5 = nn.Linear(16, 3)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1) \n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc5(x)\n",
    "        x = self.log_softmax(x)\n",
    "        return x  \n",
    "\n",
    "model = NeuralNetwork()\n",
    "\n",
    "# Define a loss function and optimizer\n",
    "criterion = nn.NLLLoss()  \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.1241\n",
      "Epoch [2/100], Loss: 0.1586\n",
      "Epoch [3/100], Loss: 0.1861\n",
      "Epoch [4/100], Loss: 0.2479\n",
      "Epoch [5/100], Loss: 0.2741\n",
      "Epoch [6/100], Loss: 0.3633\n",
      "Epoch [7/100], Loss: 0.4437\n",
      "Epoch [8/100], Loss: 0.5122\n",
      "Epoch [9/100], Loss: 0.6133\n",
      "Epoch [10/100], Loss: 0.6406\n",
      "Epoch [11/100], Loss: 0.6304\n",
      "Epoch [12/100], Loss: 0.7213\n",
      "Epoch [13/100], Loss: 0.7009\n",
      "Epoch [14/100], Loss: 0.7543\n",
      "Epoch [15/100], Loss: 0.8071\n",
      "Epoch [16/100], Loss: 0.7981\n",
      "Epoch [17/100], Loss: 0.7691\n",
      "Epoch [18/100], Loss: 0.7280\n",
      "Epoch [19/100], Loss: 0.6992\n",
      "Epoch [20/100], Loss: 0.6808\n",
      "Epoch [21/100], Loss: 0.6543\n",
      "Epoch [22/100], Loss: 0.6069\n",
      "Epoch [23/100], Loss: 0.5329\n",
      "Epoch [24/100], Loss: 0.5107\n",
      "Epoch [25/100], Loss: 0.5053\n",
      "Epoch [26/100], Loss: 0.5314\n",
      "Epoch [27/100], Loss: 0.5109\n",
      "Epoch [28/100], Loss: 0.4540\n",
      "Epoch [29/100], Loss: 0.4429\n",
      "Epoch [30/100], Loss: 0.4520\n",
      "Epoch [31/100], Loss: 0.4020\n",
      "Epoch [32/100], Loss: 0.3897\n",
      "Epoch [33/100], Loss: 0.3305\n",
      "Epoch [34/100], Loss: 0.3255\n",
      "Epoch [35/100], Loss: 0.2926\n",
      "Epoch [36/100], Loss: 0.2317\n",
      "Epoch [37/100], Loss: 0.2251\n",
      "Epoch [38/100], Loss: 0.2003\n",
      "Epoch [39/100], Loss: 0.1984\n",
      "Epoch [40/100], Loss: 0.1885\n",
      "Epoch [41/100], Loss: 0.1529\n",
      "Epoch [42/100], Loss: 0.1527\n",
      "Epoch [43/100], Loss: 0.1579\n",
      "Epoch [44/100], Loss: 0.1497\n",
      "Epoch [45/100], Loss: 0.1191\n",
      "Epoch [46/100], Loss: 0.1189\n",
      "Epoch [47/100], Loss: 0.1131\n",
      "Epoch [48/100], Loss: 0.0935\n",
      "Epoch [49/100], Loss: 0.0930\n",
      "Epoch [50/100], Loss: 0.0828\n",
      "Epoch [51/100], Loss: 0.0876\n",
      "Epoch [52/100], Loss: 0.0841\n",
      "Epoch [53/100], Loss: 0.0840\n",
      "Epoch [54/100], Loss: 0.0751\n",
      "Epoch [55/100], Loss: 0.0760\n",
      "Epoch [56/100], Loss: 0.0709\n",
      "Epoch [57/100], Loss: 0.0673\n",
      "Epoch [58/100], Loss: 0.0698\n",
      "Epoch [59/100], Loss: 0.0683\n",
      "Epoch [60/100], Loss: 0.0638\n",
      "Epoch [61/100], Loss: 0.0634\n",
      "Epoch [62/100], Loss: 0.0629\n",
      "Epoch [63/100], Loss: 0.0521\n",
      "Epoch [64/100], Loss: 0.0573\n",
      "Epoch [65/100], Loss: 0.0552\n",
      "Epoch [66/100], Loss: 0.0467\n",
      "Epoch [67/100], Loss: 0.0470\n",
      "Epoch [68/100], Loss: 0.0536\n",
      "Epoch [69/100], Loss: 0.0484\n",
      "Epoch [70/100], Loss: 0.0455\n",
      "Epoch [71/100], Loss: 0.0454\n",
      "Epoch [72/100], Loss: 0.0532\n",
      "Epoch [73/100], Loss: 0.0422\n",
      "Epoch [74/100], Loss: 0.0535\n",
      "Epoch [75/100], Loss: 0.0424\n",
      "Epoch [76/100], Loss: 0.0493\n",
      "Epoch [77/100], Loss: 0.0434\n",
      "Epoch [78/100], Loss: 0.0417\n",
      "Epoch [79/100], Loss: 0.0439\n",
      "Epoch [80/100], Loss: 0.0374\n",
      "Epoch [81/100], Loss: 0.0391\n",
      "Epoch [82/100], Loss: 0.0378\n",
      "Epoch [83/100], Loss: 0.0390\n",
      "Epoch [84/100], Loss: 0.0366\n",
      "Epoch [85/100], Loss: 0.0376\n",
      "Epoch [86/100], Loss: 0.0330\n",
      "Epoch [87/100], Loss: 0.0374\n",
      "Epoch [88/100], Loss: 0.0373\n",
      "Epoch [89/100], Loss: 0.0388\n",
      "Epoch [90/100], Loss: 0.0329\n",
      "Epoch [91/100], Loss: 0.0312\n",
      "Epoch [92/100], Loss: 0.0339\n",
      "Epoch [93/100], Loss: 0.0306\n",
      "Epoch [94/100], Loss: 0.0346\n",
      "Epoch [95/100], Loss: 0.0296\n",
      "Epoch [96/100], Loss: 0.0283\n",
      "Epoch [97/100], Loss: 0.0355\n",
      "Epoch [98/100], Loss: 0.0302\n",
      "Epoch [99/100], Loss: 0.0268\n",
      "Epoch [100/100], Loss: 0.0294\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "num_epochs = 100\n",
    "batch_size = 128  # Batch size for training\n",
    "num_batches = len(X) // batch_size\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(num_batches):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        X_batch = X[start:end]\n",
    "\n",
    "        y_batch = y[start:end]\n",
    "\n",
    "        log_probs = model(X_batch)  \n",
    "        loss = criterion(log_probs, y_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    log_probs = model(X_test)  \n",
    "    predictions = torch.argmax(log_probs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5852])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions = pd.concat([trip_id, pd.DataFrame(predictions.numpy(), columns=[\"category\"])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5852, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork()\n",
    "yhat = model(X_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_visualization.png'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualization of the model\n",
    "from torchviz import make_dot\n",
    "\n",
    "make_dot(yhat, params=dict(list(model.named_parameters()))).render(\"model_visualization\", format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train test split with stratify\n",
    "X = train.drop(columns=['category'])\n",
    "y = train['category']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=0.1, class_weight=balanced, kernel=rbf; total time=   5.8s\n",
      "[CV] END ...........C=0.1, class_weight=balanced, kernel=rbf; total time=   6.4s\n",
      "[CV] END ...........C=0.1, class_weight=balanced, kernel=rbf; total time=   6.2s\n",
      "[CV] END ..........C=0.1, class_weight=balanced, kernel=poly; total time=   4.0s\n",
      "[CV] END ...........C=0.1, class_weight=balanced, kernel=rbf; total time=   5.0s\n",
      "[CV] END ...........C=0.1, class_weight=balanced, kernel=rbf; total time=   5.8s\n",
      "[CV] END ..........C=0.1, class_weight=balanced, kernel=poly; total time=   3.9s\n",
      "[CV] END ..........C=0.1, class_weight=balanced, kernel=poly; total time=   3.6s\n",
      "[CV] END ..........C=0.1, class_weight=balanced, kernel=poly; total time=   4.1s\n",
      "[CV] END ..........C=0.1, class_weight=balanced, kernel=poly; total time=   3.9s\n",
      "[CV] END .......C=0.1, class_weight=balanced, kernel=sigmoid; total time=   5.7s\n",
      "[CV] END .......C=0.1, class_weight=balanced, kernel=sigmoid; total time=   7.3s\n",
      "[CV] END .......C=0.1, class_weight=balanced, kernel=sigmoid; total time=   6.9s\n",
      "[CV] END ........C=0.1, class_weight=balanced, kernel=linear; total time=  27.1s\n",
      "[CV] END ........C=0.1, class_weight=balanced, kernel=linear; total time=  27.6s\n",
      "[CV] END .......C=0.1, class_weight=balanced, kernel=sigmoid; total time=   7.3s\n",
      "[CV] END ........C=0.1, class_weight=balanced, kernel=linear; total time=  30.7s\n",
      "[CV] END .......C=0.1, class_weight=balanced, kernel=sigmoid; total time=   7.3s\n",
      "[CV] END ........C=0.1, class_weight=balanced, kernel=linear; total time=  34.5s\n",
      "[CV] END .............C=1, class_weight=balanced, kernel=rbf; total time=   5.5s\n",
      "[CV] END ........C=0.1, class_weight=balanced, kernel=linear; total time=  37.7s\n",
      "[CV] END .............C=1, class_weight=balanced, kernel=rbf; total time=   4.8s\n",
      "[CV] END .............C=1, class_weight=balanced, kernel=rbf; total time=   4.6s\n",
      "[CV] END .............C=1, class_weight=balanced, kernel=rbf; total time=   4.3s\n",
      "[CV] END .............C=1, class_weight=balanced, kernel=rbf; total time=   5.3s\n",
      "[CV] END ............C=1, class_weight=balanced, kernel=poly; total time=   4.2s\n",
      "[CV] END ............C=1, class_weight=balanced, kernel=poly; total time=   4.1s\n",
      "[CV] END ............C=1, class_weight=balanced, kernel=poly; total time=   3.6s\n",
      "[CV] END ............C=1, class_weight=balanced, kernel=poly; total time=   3.3s\n",
      "[CV] END ............C=1, class_weight=balanced, kernel=poly; total time=   3.2s\n",
      "[CV] END .........C=1, class_weight=balanced, kernel=sigmoid; total time=   4.6s\n",
      "[CV] END .........C=1, class_weight=balanced, kernel=sigmoid; total time=   4.9s\n",
      "[CV] END .........C=1, class_weight=balanced, kernel=sigmoid; total time=   5.6s\n",
      "[CV] END .........C=1, class_weight=balanced, kernel=sigmoid; total time=   5.0s\n",
      "[CV] END .........C=1, class_weight=balanced, kernel=sigmoid; total time=   4.8s\n",
      "[CV] END ..........C=1, class_weight=balanced, kernel=linear; total time=  57.7s\n",
      "[CV] END ..........C=1, class_weight=balanced, kernel=linear; total time= 1.0min\n",
      "[CV] END ..........C=1, class_weight=balanced, kernel=linear; total time= 1.1min\n",
      "[CV] END ..........C=1, class_weight=balanced, kernel=linear; total time= 1.1min\n",
      "[CV] END ............C=10, class_weight=balanced, kernel=rbf; total time=   3.5s\n",
      "[CV] END ............C=10, class_weight=balanced, kernel=rbf; total time=   3.7s\n",
      "[CV] END ............C=10, class_weight=balanced, kernel=rbf; total time=   3.5s\n",
      "[CV] END ............C=10, class_weight=balanced, kernel=rbf; total time=   3.7s\n",
      "[CV] END ............C=10, class_weight=balanced, kernel=rbf; total time=   3.7s\n",
      "[CV] END ...........C=10, class_weight=balanced, kernel=poly; total time=   3.1s\n",
      "[CV] END ...........C=10, class_weight=balanced, kernel=poly; total time=   3.0s\n",
      "[CV] END ...........C=10, class_weight=balanced, kernel=poly; total time=   3.0s\n",
      "[CV] END ...........C=10, class_weight=balanced, kernel=poly; total time=   2.8s\n",
      "[CV] END ..........C=1, class_weight=balanced, kernel=linear; total time= 1.3min\n",
      "[CV] END ...........C=10, class_weight=balanced, kernel=poly; total time=   3.0s\n",
      "[CV] END ........C=10, class_weight=balanced, kernel=sigmoid; total time=   3.9s\n",
      "[CV] END ........C=10, class_weight=balanced, kernel=sigmoid; total time=   3.9s\n",
      "[CV] END ........C=10, class_weight=balanced, kernel=sigmoid; total time=   4.0s\n",
      "[CV] END ........C=10, class_weight=balanced, kernel=sigmoid; total time=   3.8s\n",
      "[CV] END ........C=10, class_weight=balanced, kernel=sigmoid; total time=   3.4s\n",
      "[CV] END .........C=10, class_weight=balanced, kernel=linear; total time= 2.1min\n",
      "[CV] END .........C=10, class_weight=balanced, kernel=linear; total time= 2.2min\n",
      "[CV] END .........C=10, class_weight=balanced, kernel=linear; total time= 2.4min\n",
      "[CV] END .........C=10, class_weight=balanced, kernel=linear; total time= 2.0min\n",
      "[CV] END .........C=10, class_weight=balanced, kernel=linear; total time= 2.2min\n",
      "Best Parameters: {'C': 1, 'class_weight': 'balanced', 'kernel': 'rbf'}\n",
      "Best F1 Score (Training): 0.6367786572771648\n",
      "\n",
      "Test Accuracy: 0.6398369842078452\n",
      "Test F1 Score: 0.6381985728624274\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.83      0.82       900\n",
      "         1.0       0.65      0.40      0.49       803\n",
      "         2.0       0.35      0.74      0.48       260\n",
      "\n",
      "    accuracy                           0.64      1963\n",
      "   macro avg       0.60      0.65      0.60      1963\n",
      "weighted avg       0.68      0.64      0.64      1963\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# SVM Classifier\n",
    "svm = SVC(random_state=42)\n",
    "\n",
    "# Define the parameter grid with additional kernels\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],                     # Regularization strength\n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],  # Kernel types\n",
    "    'class_weight': ['balanced']     # Class weights for handling imbalance\n",
    "}\n",
    "\n",
    "# Grid Search with cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    svm, param_grid, \n",
    "    cv=5, scoring='f1_weighted', \n",
    "    verbose=2, n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and accuracy\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best F1 Score (Training):\", grid_search.best_score_)\n",
    "\n",
    "# Test the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate on the test set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"\\nTest Accuracy:\", accuracy)\n",
    "print(\"Test F1 Score:\", f1)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1,\n",
       " 'break_ties': False,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': 'balanced',\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': 42,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_columns = [col for col in train.columns if col not in ('category', 'trip_ID', 'visitor_nation')]\n",
    "\n",
    "test_reordered = test[train_columns]\n",
    "\n",
    "\n",
    "preds = pd.concat([test['trip_ID'], pd.Series(best_model.predict(test_reordered))], axis=1)\n",
    "preds.columns = ['trip_ID', 'category']\n",
    "preds.to_csv(\"submission_svm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, solver=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, solver=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, solver=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, solver=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=   3.7s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=   9.9s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=   3.7s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=   4.1s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=   4.1s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   4.9s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   3.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   7.9s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   4.9s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=   3.6s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=  12.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=   4.8s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=   4.6s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=   4.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=   9.8s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=   6.6s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=  10.9s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=   8.7s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=   6.0s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=adam; total time=   9.8s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=adam; total time=  17.7s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=adam; total time=  15.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=adam; total time=  15.9s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=adam; total time=  17.5s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=sgd; total time=   2.6s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=sgd; total time=   4.6s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=sgd; total time=   2.6s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=sgd; total time=   2.6s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam; total time=   9.9s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam; total time=  16.7s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam; total time=  16.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam; total time=  16.9s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam; total time=  17.7s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd; total time=   8.8s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd; total time=   9.9s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd; total time=   4.6s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd; total time=   5.9s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd; total time=   6.7s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, solver=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, solver=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, solver=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, solver=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=   4.0s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=  13.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=   4.1s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=   3.9s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=   4.0s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   4.7s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   4.5s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   5.9s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   3.7s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=   3.8s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=  13.1s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=   4.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=   4.1s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=   4.1s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=   8.8s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=   9.0s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=   9.0s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=   7.2s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=   5.9s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=adam; total time=  14.0s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=adam; total time=  12.2s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=adam; total time=  11.2s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=adam; total time=  13.6s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=adam; total time=   9.5s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=sgd; total time=   7.6s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=sgd; total time=   4.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=sgd; total time=   2.6s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam; total time=  13.8s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam; total time=  12.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam; total time=  11.0s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam; total time=  13.8s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam; total time=   9.7s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd; total time=  11.7s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd; total time=   7.6s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd; total time=   4.5s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd; total time=   8.0s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd; total time=   6.7s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, solver=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, solver=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, solver=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, solver=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=   3.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=   9.6s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=   3.9s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=   4.4s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=   3.6s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   4.7s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   3.3s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   7.4s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   4.9s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   3.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=   3.8s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=  10.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=   3.7s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=   3.8s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=   3.7s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=   8.8s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=   6.6s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=   9.8s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=   8.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=   8.2s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=adam; total time=  14.0s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=adam; total time=  14.2s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=adam; total time=  12.8s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=adam; total time=  12.6s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=adam; total time=  14.9s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=sgd; total time=   4.3s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=sgd; total time=   3.2s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=sgd; total time=   2.6s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam; total time=  14.0s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam; total time=  13.4s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam; total time=  12.8s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam; total time=  12.6s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam; total time=  15.8s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd; total time=   6.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd; total time=   9.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd; total time=   6.0s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd; total time=   5.7s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd; total time=   6.1s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   3.5s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   3.7s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   3.8s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, solver=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, solver=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, solver=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=sgd; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   4.8s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   4.4s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   4.8s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   4.2s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   4.8s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   4.3s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   4.8s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   4.3s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=  16.6s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=   8.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=  18.0s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=  17.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=  18.0s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   4.7s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   3.9s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   7.1s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   4.1s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   5.3s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=  16.8s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=   8.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=  17.4s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=  17.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=  18.0s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=   8.0s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=   6.2s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=   9.2s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=   6.6s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=   8.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=adam; total time=  21.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=adam; total time=  19.1s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=adam; total time=  11.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=adam; total time=  19.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=adam; total time=  19.1s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=sgd; total time=   5.2s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=sgd; total time=   3.3s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=sgd; total time=   3.3s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=sgd; total time=   4.9s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=sgd; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam; total time=  18.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam; total time=  19.4s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam; total time=  11.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam; total time=  19.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam; total time=  21.3s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd; total time=   7.6s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd; total time=   7.0s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd; total time=   8.0s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd; total time=   7.6s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd; total time=   9.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   3.1s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   3.6s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   3.7s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   3.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, solver=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   3.7s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   4.4s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   3.8s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   3.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   3.7s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   4.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   3.7s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   3.4s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=  17.1s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=  16.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=  17.7s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=  11.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=  17.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   4.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   3.9s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   7.0s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   4.0s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=  17.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=  16.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=  17.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=  11.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=  18.7s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=   9.9s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=  10.1s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=  10.8s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=   6.8s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=   8.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=adam; total time=  20.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=adam; total time=  20.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=adam; total time=  21.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=adam; total time=  19.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=adam; total time=  19.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=sgd; total time=   5.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=sgd; total time=   3.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=sgd; total time=   3.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=sgd; total time=   4.8s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=sgd; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam; total time=  19.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam; total time=  19.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam; total time=  22.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam; total time=  19.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam; total time=  19.7s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd; total time=   7.9s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd; total time=   6.7s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd; total time=   8.0s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd; total time=   8.0s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd; total time=   9.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, solver=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, solver=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   1.3s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   3.8s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   3.8s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   4.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   3.7s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   3.7s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   4.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=  17.3s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=  16.8s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=  17.6s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=   6.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=  17.9s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   4.9s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   4.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   7.1s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   4.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=  18.2s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=  16.8s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=  17.4s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=   6.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=  18.1s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=   7.4s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=   6.1s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=   9.5s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=   6.7s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=   7.9s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=adam; total time=  13.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=adam; total time=  20.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=adam; total time=  22.6s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=adam; total time=  21.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=adam; total time=  26.2s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=sgd; total time=   7.1s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=sgd; total time=   4.8s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=sgd; total time=   5.2s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=sgd; total time=   7.1s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, solver=sgd; total time=   3.6s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam; total time=  19.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam; total time=  26.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam; total time=  26.1s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam; total time=  18.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam; total time=  25.9s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd; total time=  10.4s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd; total time=   9.8s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd; total time=  11.4s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd; total time=  10.7s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd; total time=  12.5s\n",
      "Best Parameters: {'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "Training Accuracy: 0.7152866242038216\n",
      "Test Accuracy: 0.7121752419765665\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.84      0.81       900\n",
      "         1.0       0.65      0.72      0.68       803\n",
      "         2.0       0.60      0.24      0.34       260\n",
      "\n",
      "    accuracy                           0.71      1963\n",
      "   macro avg       0.68      0.60      0.61      1963\n",
      "weighted avg       0.70      0.71      0.70      1963\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define the MLPClassifier with parameter tuning\n",
    "mlp = MLPClassifier(max_iter=500, random_state=42)\n",
    "\n",
    "# Define hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (100, 50), (50, 50, 50)],  # Different architectures\n",
    "    'activation': ['relu', 'tanh'],                                  # Activation functions\n",
    "    'solver': ['adam', 'sgd'],                                       # Optimizers\n",
    "    'alpha': [0.0001, 0.001, 0.01],                                  # Regularization strength\n",
    "    'learning_rate': ['constant', 'adaptive'],                       # Learning rate strategies\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=mlp,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model and evaluate on the test set\n",
    "best_mlp = grid_search.best_estimator_\n",
    "y_pred = best_mlp.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Training Accuracy:\", grid_search.best_score_)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_columns = [col for col in train.columns if col not in ('category', 'trip_ID', 'visitor_nation')]\n",
    "\n",
    "test_reordered = test[train_columns]\n",
    "\n",
    "preds = pd.concat([test['trip_ID'], pd.Series(best_mlp.predict(test_reordered))], axis=1)\n",
    "preds.columns = ['trip_ID', 'category']\n",
    "preds.to_csv(\"submission_mlp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/dyuthi/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.1s[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, splitter=best; total time=   0.1s[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=5, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=5, min_samples_split=5, splitter=random; total time=   0.0s[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=5, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=5, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=5, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=5, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=5, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=5, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=5, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=5, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=5, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=5, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=5, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=5, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=5, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=5, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=5, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=5, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=5, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=5, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=10, min_samples_leaf=5, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=5, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=5, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=5, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=5, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=5, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=5, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=5, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=5, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=5, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=5, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=5, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=5, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=5, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=5, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=5, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=5, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=5, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=5, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=log_loss, max_depth=20, min_samples_leaf=5, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "Best Parameters: {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10, 'splitter': 'best'}\n",
      "\n",
      "Test Accuracy: 0.6805909322465614\n",
      "Test F1 Score: 0.6865027450222471\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.79      0.81       900\n",
      "         1.0       0.66      0.56      0.61       803\n",
      "         2.0       0.42      0.68      0.52       260\n",
      "\n",
      "    accuracy                           0.68      1963\n",
      "   macro avg       0.64      0.68      0.64      1963\n",
      "weighted avg       0.70      0.68      0.69      1963\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[709 165  26]\n",
      " [132 449 222]\n",
      " [ 15  67 178]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],  # Splitting criteria\n",
    "    'splitter': ['best', 'random'],               # How to split nodes\n",
    "    'max_depth': [10, 20],              # Maximum depth of the tree\n",
    "    'min_samples_split': [5, 10],              # Minimum samples required to split a node\n",
    "    'min_samples_leaf': [2, 5],                # Minimum samples required in a leaf node\n",
    "    'class_weight': ['balanced']            # Adjust class weights for imbalance\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    dt_model, param_grid, \n",
    "    cv=5, scoring='f1_weighted', \n",
    "    verbose=2, n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the best model\n",
    "best_dt_model = grid_search.best_estimator_\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Test the best model\n",
    "y_pred = best_dt_model.predict(X_test)\n",
    "\n",
    "# Evaluate performance on the test set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"\\nTest Accuracy:\", accuracy)\n",
    "print(\"Test F1 Score:\", f1)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_columns = [col for col in train.columns if col not in ('category', 'trip_ID', 'visitor_nation')]\n",
    "\n",
    "test_reordered = test[train_columns]\n",
    "\n",
    "\n",
    "preds = pd.concat([test['trip_ID'], pd.Series(best_dt_model.predict(test_reordered))], axis=1)\n",
    "preds.columns = ['trip_ID', 'category']\n",
    "preds.to_csv(\"submission_dt.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
