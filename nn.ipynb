{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_preprocessed.csv')\n",
    "test = pd.read_csv('test_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = [ 'mainland_nights', 'island_nights', 'ratio', 'total_nights', 'male_count', 'female_count', 'total_travellers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train[num_features] = scaler.fit_transform(train[num_features])\n",
    "test[num_features] = scaler.transform(test[num_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(columns='visitor_nation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_id = test['trip_ID']\n",
    "test_data = test.drop(columns='trip_ID')\n",
    "\n",
    "categories = train['category']\n",
    "train_data = train.drop(columns='category')\n",
    "\n",
    "assert (train_data.columns == test_data.columns).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(train_data.values, dtype=torch.float32)\n",
    "y = torch.tensor(categories.values, dtype=torch.long)\n",
    "\n",
    "X_test = torch.tensor(test_data.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X, y = smote.fit_resample(X, y)\n",
    "\n",
    "# X = torch.tensor(X, dtype=torch.float32)\n",
    "# y = torch.tensor(y, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swetha/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(27, 128)\n",
    "        self.fc2 = nn.Linear(128, 64) \n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 16)\n",
    "        self.fc5 = nn.Linear(16, 3)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1) \n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc5(x)\n",
    "        x = self.log_softmax(x)\n",
    "        return x  \n",
    "\n",
    "model = NeuralNetwork()\n",
    "\n",
    "# Define a loss function and optimizer\n",
    "criterion = nn.NLLLoss()  \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.1241\n",
      "Epoch [2/100], Loss: 0.1586\n",
      "Epoch [3/100], Loss: 0.1861\n",
      "Epoch [4/100], Loss: 0.2479\n",
      "Epoch [5/100], Loss: 0.2741\n",
      "Epoch [6/100], Loss: 0.3633\n",
      "Epoch [7/100], Loss: 0.4437\n",
      "Epoch [8/100], Loss: 0.5122\n",
      "Epoch [9/100], Loss: 0.6133\n",
      "Epoch [10/100], Loss: 0.6406\n",
      "Epoch [11/100], Loss: 0.6304\n",
      "Epoch [12/100], Loss: 0.7213\n",
      "Epoch [13/100], Loss: 0.7009\n",
      "Epoch [14/100], Loss: 0.7543\n",
      "Epoch [15/100], Loss: 0.8071\n",
      "Epoch [16/100], Loss: 0.7981\n",
      "Epoch [17/100], Loss: 0.7691\n",
      "Epoch [18/100], Loss: 0.7280\n",
      "Epoch [19/100], Loss: 0.6992\n",
      "Epoch [20/100], Loss: 0.6808\n",
      "Epoch [21/100], Loss: 0.6543\n",
      "Epoch [22/100], Loss: 0.6069\n",
      "Epoch [23/100], Loss: 0.5329\n",
      "Epoch [24/100], Loss: 0.5107\n",
      "Epoch [25/100], Loss: 0.5053\n",
      "Epoch [26/100], Loss: 0.5314\n",
      "Epoch [27/100], Loss: 0.5109\n",
      "Epoch [28/100], Loss: 0.4540\n",
      "Epoch [29/100], Loss: 0.4429\n",
      "Epoch [30/100], Loss: 0.4520\n",
      "Epoch [31/100], Loss: 0.4020\n",
      "Epoch [32/100], Loss: 0.3897\n",
      "Epoch [33/100], Loss: 0.3305\n",
      "Epoch [34/100], Loss: 0.3255\n",
      "Epoch [35/100], Loss: 0.2926\n",
      "Epoch [36/100], Loss: 0.2317\n",
      "Epoch [37/100], Loss: 0.2251\n",
      "Epoch [38/100], Loss: 0.2003\n",
      "Epoch [39/100], Loss: 0.1984\n",
      "Epoch [40/100], Loss: 0.1885\n",
      "Epoch [41/100], Loss: 0.1529\n",
      "Epoch [42/100], Loss: 0.1527\n",
      "Epoch [43/100], Loss: 0.1579\n",
      "Epoch [44/100], Loss: 0.1497\n",
      "Epoch [45/100], Loss: 0.1191\n",
      "Epoch [46/100], Loss: 0.1189\n",
      "Epoch [47/100], Loss: 0.1131\n",
      "Epoch [48/100], Loss: 0.0935\n",
      "Epoch [49/100], Loss: 0.0930\n",
      "Epoch [50/100], Loss: 0.0828\n",
      "Epoch [51/100], Loss: 0.0876\n",
      "Epoch [52/100], Loss: 0.0841\n",
      "Epoch [53/100], Loss: 0.0840\n",
      "Epoch [54/100], Loss: 0.0751\n",
      "Epoch [55/100], Loss: 0.0760\n",
      "Epoch [56/100], Loss: 0.0709\n",
      "Epoch [57/100], Loss: 0.0673\n",
      "Epoch [58/100], Loss: 0.0698\n",
      "Epoch [59/100], Loss: 0.0683\n",
      "Epoch [60/100], Loss: 0.0638\n",
      "Epoch [61/100], Loss: 0.0634\n",
      "Epoch [62/100], Loss: 0.0629\n",
      "Epoch [63/100], Loss: 0.0521\n",
      "Epoch [64/100], Loss: 0.0573\n",
      "Epoch [65/100], Loss: 0.0552\n",
      "Epoch [66/100], Loss: 0.0467\n",
      "Epoch [67/100], Loss: 0.0470\n",
      "Epoch [68/100], Loss: 0.0536\n",
      "Epoch [69/100], Loss: 0.0484\n",
      "Epoch [70/100], Loss: 0.0455\n",
      "Epoch [71/100], Loss: 0.0454\n",
      "Epoch [72/100], Loss: 0.0532\n",
      "Epoch [73/100], Loss: 0.0422\n",
      "Epoch [74/100], Loss: 0.0535\n",
      "Epoch [75/100], Loss: 0.0424\n",
      "Epoch [76/100], Loss: 0.0493\n",
      "Epoch [77/100], Loss: 0.0434\n",
      "Epoch [78/100], Loss: 0.0417\n",
      "Epoch [79/100], Loss: 0.0439\n",
      "Epoch [80/100], Loss: 0.0374\n",
      "Epoch [81/100], Loss: 0.0391\n",
      "Epoch [82/100], Loss: 0.0378\n",
      "Epoch [83/100], Loss: 0.0390\n",
      "Epoch [84/100], Loss: 0.0366\n",
      "Epoch [85/100], Loss: 0.0376\n",
      "Epoch [86/100], Loss: 0.0330\n",
      "Epoch [87/100], Loss: 0.0374\n",
      "Epoch [88/100], Loss: 0.0373\n",
      "Epoch [89/100], Loss: 0.0388\n",
      "Epoch [90/100], Loss: 0.0329\n",
      "Epoch [91/100], Loss: 0.0312\n",
      "Epoch [92/100], Loss: 0.0339\n",
      "Epoch [93/100], Loss: 0.0306\n",
      "Epoch [94/100], Loss: 0.0346\n",
      "Epoch [95/100], Loss: 0.0296\n",
      "Epoch [96/100], Loss: 0.0283\n",
      "Epoch [97/100], Loss: 0.0355\n",
      "Epoch [98/100], Loss: 0.0302\n",
      "Epoch [99/100], Loss: 0.0268\n",
      "Epoch [100/100], Loss: 0.0294\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 128  # Batch size for training\n",
    "num_batches = len(X) // batch_size\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(num_batches):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        X_batch = X[start:end]\n",
    "\n",
    "        y_batch = y[start:end]\n",
    "\n",
    "        log_probs = model(X_batch)  \n",
    "        loss = criterion(log_probs, y_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    log_probs = model(X_test)  \n",
    "    predictions = torch.argmax(log_probs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5852])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions = pd.concat([trip_id, pd.DataFrame(predictions.numpy(), columns=[\"category\"])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5852, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork()\n",
    "yhat = model(X_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_visualization.png'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "make_dot(yhat, params=dict(list(model.named_parameters()))).render(\"model_visualization\", format=\"png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
